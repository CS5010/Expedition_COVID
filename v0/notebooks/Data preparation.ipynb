{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction\n",
    "This file converts the cleaned raw dataset into a single merged file that the TFTModel can work on. The script version available at [prepare_data.py](../script/prepare_data.py).\n",
    "\n",
    "If you need to change the input feature set, only add that info in the `\"data\"` section of the json configuration  file. This notebook will update the rest (at least feature column mappings and locations) . If you have pivoted dynamic feature and need to melt that date columns, make sure to keep the feature name as `string` in `\"dynamic_features_map\"`. If it is already melted and your dynamic file has a `Date` column, `list` or `string` format both is fine.\n",
    "\n",
    "In the final output all null values are replaced with 0. If you don't want that, comment that out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "sys.path.append( '..' )\n",
    "from Class.DataMerger import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Googe drive\n",
    "Not needed. But set `running_on_colab = True` if using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "running_on_colab = False\n",
    "\n",
    "if running_on_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    %cd /content/drive/My Drive/COVID-19-forecast/src/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Input\n",
    "If running on colab, modify the below paths accordingly. Note that this config.json is different from the config.json in TF2 folder as that is for the old dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class args:\n",
    "    # folder where the cleaned feature file are at\n",
    "    # dataPath = '../../dataset_raw/CovidDecember12-2021'\n",
    "    dataPath = '../../dataset_raw/CovidMay17-2022'\n",
    "\n",
    "\n",
    "    supportPath = '../../dataset_raw/Support files'\n",
    "    outputPath = '../2022_May/'\n",
    "    configPath = '../config_2022_May.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file loaded from ../config_2022_May.json\n"
     ]
    }
   ],
   "source": [
    "# create output path if it doesn't exist\n",
    "if not os.path.exists(args.outputPath):\n",
    "    print(f'Creating output directory {args.outputPath}')\n",
    "    os.makedirs(args.outputPath, exist_ok=True)\n",
    "\n",
    "# load config file\n",
    "with open(args.configPath) as inputFile:\n",
    "    config = json.load(inputFile)\n",
    "    print(f'Config file loaded from {args.configPath}')\n",
    "    inputFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data merger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Total features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get merger class\n",
    "dataMerger = DataMerger(config, args.dataPath, args.supportPath)\n",
    "total_df = dataMerger.get_all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_path_total = os.path.join(args.outputPath, 'Total.csv') \n",
    "print(f'Writing total data to {output_path_total}\\n')\n",
    "total_df.round(4).to_csv(output_path_total, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique counties present 3142\n",
      "Merging feature Age Distribution.csv with length 3142\n",
      "Merging feature Air Pollution.csv with length 3142\n",
      "Merging feature Health Disparities.csv with length 3142\n",
      "\n",
      "Merged static features have 3142 counties\n",
      "   FIPS  AgeDist  AirPollution  HealthDisp\n",
      "0  1001   0.5017        0.5210      0.2606\n",
      "1  1003   0.6095        0.4371      0.2039\n",
      "2  1005   0.5797        0.5090      0.6562\n",
      "3  1007   0.5427        0.4910      0.5320\n",
      "4  1009   0.5755        0.5210      0.4462\n",
      "Reading Disease Spread.csv\n",
      "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
      "Length 2545020.\n",
      "Reading Transmissible Cases.csv\n",
      "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
      "Length 2545020.\n",
      "Reading Vaccination.csv\n",
      "Min date 2020-12-13 00:00:00, max date 2022-05-17 00:00:00\n",
      "Length 1679704.\n",
      "Reading Social Distancing.csv\n",
      "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
      "Length 2545020.\n",
      "Total dynamic feature shape (2587742, 7)\n",
      "   FIPS              Name       Date  DiseaseSpread  Transmission  \\\n",
      "0  1001  Alabama, Autauga 2020-02-28            0.0           0.0   \n",
      "1  1003  Alabama, Baldwin 2020-02-28            0.0           0.0   \n",
      "2  1005  Alabama, Barbour 2020-02-28            0.0           0.0   \n",
      "3  1007     Alabama, Bibb 2020-02-28            0.0           0.0   \n",
      "4  1009   Alabama, Blount 2020-02-28            0.0           0.0   \n",
      "\n",
      "   VaccinationFull  SocialDist  \n",
      "0              NaN       1.000  \n",
      "1              NaN       1.000  \n",
      "2              NaN       0.825  \n",
      "3              NaN       1.000  \n",
      "4              NaN       1.000  \n",
      "Merging all features\n",
      "Total merged data shape (2545020, 11)\n",
      "Missing percentage in total data\n",
      "VaccinationFull    35.68\n",
      "FIPS                0.00\n",
      "AgeDist             0.00\n",
      "AirPollution        0.00\n",
      "HealthDisp          0.00\n",
      "Name                0.00\n",
      "Date                0.00\n",
      "DiseaseSpread       0.00\n",
      "Transmission        0.00\n",
      "SocialDist          0.00\n",
      "Cases               0.00\n",
      "dtype: float64\n",
      "Filling null values with 0\n",
      "Writing total data to ../2022_May/Total.csv\n",
      "\n",
      "Updating config file\n",
      "static locs: [0, 1, 2]\n",
      "future locs: [7, 8, 9, 10, 11, 12, 13, 14]\n",
      "target loc: 15. total input 16\n",
      "col_mappings: Static ['AgeDist', 'AirPollution', 'HealthDisp']\n",
      "col_mappings: Future ['LinearSpace', 'Constant', 'LinearTime', 'P2Time', 'P3Time', 'P4Time', 'CosWeekly', 'SinWeekly']\n",
      "col_mappings: Known Regular  ['AgeDist', 'AirPollution', 'HealthDisp', 'DiseaseSpread', 'Transmission', 'VaccinationFull', 'SocialDist']\n"
     ]
    }
   ],
   "source": [
    "print('Updating config file')\n",
    "dataMerger.update_config(args.configPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rurality cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing based on top 100 counties by population\n",
      "Writing population cut data to ../2022_May/Population_cut.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can be used as cache to perform different rurality or population cuts\n",
    "# total_df = pd.read_csv(output_path_total)\n",
    "\n",
    "# you can define Rurality cut in 'data'->'support'\n",
    "# Rurality cut has to be set true. and also set lower and upper limit in RuralityRange and/or MADRange\n",
    "# having -1 in either of these two will result in ignoring that key\n",
    "if dataMerger.need_rurality_cut():\n",
    "    rurality_df = dataMerger.rurality_cut(total_df)\n",
    "\n",
    "    output_path_rurality_cut = os.path.join(args.outputPath, 'Rurality_cut.csv')\n",
    "    print(f'Writing rurality cut data to {output_path_rurality_cut}\\n')\n",
    "    rurality_df.round(4).to_csv(output_path_rurality_cut, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Population cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# you can define 'Population cut' in 'data'->'support'\n",
    "# this means how many of top counties you want to keep\n",
    "if dataMerger.need_population_cut():\n",
    "    top_df = dataMerger.population_cut(total_df)\n",
    "\n",
    "    output_path_population_cut = os.path.join(args.outputPath, 'Population_cut.csv')\n",
    "    print(f'Writing population cut data to {output_path_population_cut}\\n')\n",
    "    top_df.round(4).to_csv(output_path_population_cut, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run TFT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now you can use the [TFT_on_top_500_counties.ipynb](/Source/notebooks/TFT_on_top_500_counties.ipynb) notebook to run experiment on top 500 counties."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f82c0d4b75d1a522b549257adf6e3ea321f1ee050a595ab76efcf522f2572b2a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}