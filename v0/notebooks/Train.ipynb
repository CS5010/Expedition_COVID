{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCsw1KjFX1PP"
      },
      "source": [
        "# Introduction\n",
        "This is modified a notebook version of the TFT model script written in TF2 folder. This works with both the old and new dataset.If you are switching dataset, be sure to change both input csv and `config.json` files. They can be found in the `TF2\\Notebooks\\2022_May` or `TF2\\Notebooks\\2021_Nov` folder.  This notebook used the input files in `TF2\\Notebooks\\2022_May` folder. You can recreate them using the `Data preparation` notebook in this same folder. For a fresh model training, remove any files from the `checkpoint` folder.\n",
        "\n",
        "It is modified to run on colab. If you want to run on your local machine, you can use the model scripts in the TF2 folder instead. Run the model on GPU or reduce `epochs` in `config.json`.\n",
        "\n",
        "The input dataset is splitted into three parts here based on the following dates\n",
        "\n",
        "* `Train`: From `2020-02-28` to `2021-11-22`\n",
        "* `Validation`: From `2021-11-23` to `2022-02-18`\n",
        "* `Test`: From `2022-02-19` to `2022-05-17`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvhjFLeL6GwE"
      },
      "source": [
        "# Initial Setup\n",
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq2WaGb23m4h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os, gc, json\n",
        "import pandas as pd\n",
        "from pandas import to_datetime\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Apply the default theme\n",
        "sns.set_theme()\n",
        "sns.set(font_scale = 1.5)\n",
        "\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Apply the default theme\n",
        "sns.set_theme()\n",
        "sns.set(font_scale = 1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append( '..' )\n",
        "from script.utils import train_validation_test_split, scale_back, calculate_result, sumCases\n",
        "from Class.Trainer import Trainer\n",
        "from Class.ParameterManager import ParameterManager\n",
        "from Class.DataProcessor import DataProcessor\n",
        "from Class.Plotter import PlotResults, PlotWeights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHfi9sgDPca3",
        "outputId": "08eb578e-22f9-4e68-dda1-a86d1f6a55bb"
      },
      "outputs": [],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAXjXa01ZxMr"
      },
      "source": [
        "## Adding google drive\n",
        "Set `running_on_colab= True` if running on Google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMLUJkNto9s5",
        "outputId": "45fd13c2-5721-4a9d-9d95-9aa823bfb142"
      },
      "outputs": [],
      "source": [
        "running_on_colab = False\n",
        "\n",
        "if running_on_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd /content/drive/My Drive/Projects/Covid/TF2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO8CwyyG6C5L"
      },
      "source": [
        "## Setting up folders\n",
        "The current folder has the following structure\n",
        "\n",
        "* 2022_May\n",
        "  * Top_500.csv\n",
        "* config_2022_May.json\n",
        "* output\n",
        "  * checkpoints\n",
        "  * figures\n",
        "\n",
        "## For new dataset\n",
        "You can collect `Top_500.csv` and `config.json` for new dataset is in the `TF2\\Notebooks\\2022_May` folder. \n",
        "\n",
        "### For the old dataset \n",
        "Collect `Top_500.csv` and `config.json` from the `TF2\\Notebooks\\2021_Nov` folder. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class args:\n",
        "    # folder where the cleaned feature file are at\n",
        "    # dataPath = ''../2021_Nov/Population_cut.csv''\n",
        "    dataPath = '../2022_May/Population_cut.csv'\n",
        "\n",
        "    outputPath = '../output/'\n",
        "    configPath = '../config_2022_May.json'\n",
        "    checkpoint = os.path.join(outputPath, 'checkpoints')\n",
        "    restore = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emPIKC5x40L8"
      },
      "outputs": [],
      "source": [
        "# output paths\n",
        "checkpoint_folder = args.checkpoint\n",
        "figure_folder = os.path.join(args.outputPath, \"figures\")\n",
        "\n",
        "# this eventually creates output folder if it doesn't exist\n",
        "if not os.path.exists(checkpoint_folder):\n",
        "    os.makedirs(checkpoint_folder, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(figure_folder):\n",
        "    os.makedirs(figure_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV4r9ohA0vOW"
      },
      "outputs": [],
      "source": [
        "print(f'Loading config.json from {args.configPath}')\n",
        "with open(args.configPath) as inputfile:\n",
        "    config = json.load(inputfile)\n",
        "    inputfile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL-GCKH1ChBC"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HQ0hkih1ulOo",
        "outputId": "35c9b4be-94df-4fdc-94ce-da7b264e59a9"
      },
      "outputs": [],
      "source": [
        "print(f'Loading input data from {args.dataPath}')\n",
        "df = pd.read_csv(args.dataPath)\n",
        "print(f'Input feature file shape {df.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhixFDqFTqn5"
      },
      "outputs": [],
      "source": [
        "df['Date'] = to_datetime(df['Date']) \n",
        "df['FIPS'] = df['FIPS'].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlzdcpMvQxEE"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameter manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameterManager = ParameterManager(config)\n",
        "print(f'Column mappings: {parameterManager.col_mappings}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train validation test split and Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data, validation_data, test_data, target_scaler = train_validation_test_split(df, parameterManager, scale=True)\n",
        "print(f'Number train data is {train_data.shape[0]}, validation {validation_data.shape[0]}, test {test_data.shape[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataProcessor = DataProcessor(\n",
        "    parameterManager.total_sequence_length, parameterManager.col_mappings, parameterManager.data_params\n",
        ")\n",
        "\n",
        "train_batch = dataProcessor.prepare_batch(train_data, train=True)\n",
        "validation_batch = dataProcessor.prepare_batch(validation_data)\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_history(history:dict,  figure_path:str=None, show=False):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(18, 8), sharex=True)\n",
        "    x = range(1, len(history['train_loss'])+1)\n",
        "\n",
        "    # label_text   = [f'{int(loc/1000)}k' for loc in plt.yticks()[0]]\n",
        "    # ax.set_yticklabels(label_text)\n",
        "\n",
        "    ax[0].set_title('Training history')\n",
        "    ax[0].plot(x, history['train_loss'], color='blue', label='Train loss')\n",
        "    ax[0].set_xlabel('Epoch')\n",
        "    ax[0].set_ylabel('Mean Squared Error of daily covid cases')\n",
        "    ax[0].legend()\n",
        "\n",
        "    ax[1].set_title('Validation history')\n",
        "    ax[1].plot(x, history['validation_loss'], color='green', label='Validation loss')\n",
        "    ax[1].set_xlabel('Epoch')\n",
        "    ax[1].set_ylabel('Mean Squared Error of daily covid cases')\n",
        "    ax[1].legend()\n",
        "\n",
        "    fig.tight_layout()\n",
        "    if figure_path:\n",
        "        plt.savefig(figure_path)\n",
        "    if show:\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = Trainer(parameterManager)\n",
        "model = trainer.create_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizer and Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer_params = parameterManager.optimizer_params\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=optimizer_params['learning_rate'], clipnorm=optimizer_params['clipnorm']\n",
        ")\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
        "checkpointManager = tf.train.CheckpointManager(checkpoint, checkpoint_folder, max_to_keep=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if args.restore and checkpointManager.latest_checkpoint:\n",
        "    model = trainer.load_from_checkpoint(checkpoint, checkpointManager.latest_checkpoint)\n",
        "    if model is None:\n",
        "        sys.exit(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = trainer.fit(\n",
        "    model, optimizer, train_batch, validation_batch, checkpointManager\n",
        ")\n",
        "\n",
        "plot_history(history, os.path.join(figure_folder, 'history.png'), show=True)\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the best checkpoint by validation loss\n",
        "model = trainer.load_from_checkpoint(checkpoint, checkpointManager.latest_checkpoint)\n",
        "if model is None:\n",
        "    sys.exit(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_batch = dataProcessor.prepare_batch(train_data)\n",
        "train_preds, train_actuals, train_attn_weights = trainer.predict(model, train_batch)\n",
        "\n",
        "train_actuals = scale_back(train_actuals, target_scaler, parameterManager.target_sequence_length)\n",
        "train_preds = scale_back(train_preds, target_scaler, parameterManager.target_sequence_length)\n",
        "\n",
        "train_mae, train_rmse, train_smape = calculate_result(train_actuals, train_preds)\n",
        "print(f'Train MAE {train_mae}, RMSE {train_rmse}, SMAPE {train_smape}')\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_preds, validation_actuals, _ = trainer.predict(model, validation_batch)\n",
        "\n",
        "validation_preds = scale_back(validation_preds, target_scaler, parameterManager.target_sequence_length)\n",
        "validation_actuals = scale_back(validation_actuals,  target_scaler, parameterManager.target_sequence_length)\n",
        "\n",
        "validation_mae, validation_rmse, validation_smape = calculate_result(validation_actuals, validation_preds)\n",
        "print(f'Validation MAE {validation_mae}, RMSE {validation_rmse}, SMAPE {validation_smape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_batch = dataProcessor.prepare_batch(test_data)\n",
        "test_preds, test_actuals, _ = trainer.predict(model, test_batch)\n",
        "\n",
        "test_actuals = scale_back(test_actuals, target_scaler, parameterManager.target_sequence_length) \n",
        "test_preds = scale_back(test_preds, target_scaler, parameterManager.target_sequence_length)\n",
        "\n",
        "test_mae, test_rmse, test_smape = calculate_result(test_actuals, test_preds)\n",
        "print(f'Test MAE {test_mae}, RMSE {test_rmse}, SMAPE {test_smape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del model\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Result plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_locations = df[parameterManager.col_mappings['ID']].nunique().values[0]\n",
        "print(f'Number of locations {number_of_locations}')\n",
        "locs = df[parameterManager.col_mappings['ID']].iloc[:number_of_locations, 0].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "targets, predictions = sumCases(train_actuals, train_preds, number_of_locations)\n",
        "\n",
        "resultPlotter = PlotResults(targets, predictions, parameterManager.train_start, locs, figure_folder)\n",
        "plot_title = f'Summed plot (train) MAE {train_mae:0.3f}, RMSE {train_rmse:0.3f}'\n",
        "\n",
        "resultPlotter.makeSummedPlot(plot_title, figure_name='Summed plot - train', figsize=(24, 8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "targets, predictions = sumCases(validation_actuals, validation_preds, number_of_locations)\n",
        "resultPlotter = PlotResults(targets, predictions, parameterManager.validation_start, locs, figure_folder)\n",
        "plot_title = f'Summed plot (Validation) MAE {validation_mae:0.3f}, RMSE {validation_rmse:0.3f}, SMAPE {validation_smape:0.3f}'\n",
        "\n",
        "resultPlotter.makeSummedPlot(plot_title, figure_name='Summed plot - validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "targets, predictions = sumCases(test_actuals, test_preds, number_of_locations)\n",
        "PlotC = PlotResults(targets, predictions, parameterManager.test_start, locs, figure_folder)\n",
        "plot_title = f'Summed plot (Validation) MAE {validation_mae:0.3f}, RMSE {validation_rmse:0.3f}, SMAPE {validation_smape:0.3f}'\n",
        "\n",
        "PlotC.makeSummedPlot(plot_title, figure_name='Summed plot - test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotter = PlotWeights(parameterManager.col_mappings, train_attn_weights, figure_folder, show=True)\n",
        "\"\"\"## Static variables\"\"\"\n",
        "\n",
        "plotter.plot_static_weights()\n",
        "\n",
        "\"\"\"## Future known input\"\"\"\n",
        "\n",
        "plotter.plot_future_weights()\n",
        "\n",
        "\"\"\"## Observed weights\"\"\"\n",
        "\n",
        "plotter.plotObservedWeights()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "77iIQhnG6b2y",
        "IY2OVkjn6tQp"
      ],
      "name": "TFT on top 500 counties.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "f82c0d4b75d1a522b549257adf6e3ea321f1ee050a595ab76efcf522f2572b2a"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
