{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jp_MQeY9Hob"
      },
      "source": [
        "# Introduction\n",
        "This file converts the cleaned raw dataset into a single merged file that the TFTModel can work on. The script version available at [prepare_data.py](../script/prepare_data.py).\n",
        "\n",
        "If you need to change the input feature set, only add that info in the `\"data\"` section of the json configuration  file. This notebook will update the rest (at least feature column mappings and locations) . If you have pivoted dynamic feature and need to melt that date columns, make sure to keep the feature name as `string` in `\"dynamic_features_map\"`. If it is already melted and your dynamic file has a `Date` column, `list` or `string` format both is fine.\n",
        "\n",
        "In the final output all null values are replaced with 0. If you don't want that, comment that out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI10VjY39Hof"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1M2WLI7D9Hog"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import sys\n",
        "sys.path.append( '..' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fy3zL-09Hoh"
      },
      "source": [
        "# Setup storage\n",
        "\n",
        "You would need the `CovidMay17-2022` and `Support files` folders for the dateset. And the v0 folder for the codes. Upload both of them in the place where you are running the code from. My folder structure looks like this\n",
        "* dataset_raw\n",
        "    * CovidMay17-2022\n",
        "    * Support files\n",
        "* v0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMX9mq7-9Hoi"
      },
      "source": [
        "## Googe drive\n",
        "Not needed, since you can run this on CPU. But set `running_on_colab = True` if using. Also update the `cd` path so that it points to the notebook folder in your drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "405O2njt9Hoi",
        "outputId": "06b68e92-5354-43ff-b93e-1e5b9502f15d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Projects/Covid/v0/notebooks\n"
          ]
        }
      ],
      "source": [
        "running_on_colab = False\n",
        "\n",
        "if running_on_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd /content/drive/My Drive/Projects/Covid/v0/notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlaIcaHc9Hoi"
      },
      "source": [
        "## Input\n",
        "If running on colab, modify the below paths accordingly. Note that this config.json is different from the config.json in TF2 folder as that is for the old dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kKXlhpDi9Hoj"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from Class.DataMerger import *\n",
        "\n",
        "@dataclass\n",
        "class args:\n",
        "    # folder where the cleaned feature file are at\n",
        "    # dataPath = '../../dataset_raw/CovidDecember12-2021'\n",
        "    dataPath = '../../dataset_raw/CovidMay17-2022'\n",
        "    supportPath = '../../dataset_raw/Support files'\n",
        "    outputPath = '../2022_May/'\n",
        "    configPath = '../config_2022_May.json'\n",
        "    cachePath = None # '../2022_May/Total.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE7F4cXP9Hok",
        "outputId": "c5927406-1491-4ae3-d252-32e1f2f3f231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config file loaded from ../config_2022_May.json\n"
          ]
        }
      ],
      "source": [
        "# create output path if it doesn't exist\n",
        "if not os.path.exists(args.outputPath):\n",
        "    print(f'Creating output directory {args.outputPath}')\n",
        "    os.makedirs(args.outputPath, exist_ok=True)\n",
        "\n",
        "# load config file\n",
        "with open(args.configPath) as inputFile:\n",
        "    config = json.load(inputFile)\n",
        "    print(f'Config file loaded from {args.configPath}')\n",
        "    inputFile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BgfTz2F9Hol"
      },
      "source": [
        "# Data merger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VtM_7Mh9Hol"
      },
      "source": [
        "## Total features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLrT8EfF9Hom",
        "outputId": "3a83f81f-7cc2-404e-a076-43372808dc0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique counties present 3142\n",
            "Merging feature Age Distribution.csv with length 3142\n",
            "Merging feature Air Pollution.csv with length 3142\n",
            "Merging feature Health Disparities.csv with length 3142\n",
            "\n",
            "Merged static features have 3142 counties\n",
            "   FIPS  AgeDist  AirPollution  HealthDisp\n",
            "0  1001   0.5017        0.5210      0.2606\n",
            "1  1003   0.6095        0.4371      0.2039\n",
            "2  1005   0.5797        0.5090      0.6562\n",
            "3  1007   0.5427        0.4910      0.5320\n",
            "4  1009   0.5755        0.5210      0.4462\n",
            "Reading Disease Spread.csv\n",
            "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
            "Length 2545020.\n",
            "\n",
            "Reading Transmissible Cases.csv\n",
            "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
            "Length 2545020.\n",
            "\n",
            "Reading Vaccination.csv\n",
            "Min date 2020-12-13 00:00:00, max date 2022-05-17 00:00:00\n",
            "Length 1679704.\n",
            "\n",
            "Reading Social Distancing.csv\n",
            "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
            "Length 2545020.\n",
            "\n",
            "Total dynamic feature shape (2587742, 7)\n",
            "   FIPS              Name       Date  DiseaseSpread  Transmission  \\\n",
            "0  1001  Alabama, Autauga 2020-02-28            0.0           0.0   \n",
            "1  1003  Alabama, Baldwin 2020-02-28            0.0           0.0   \n",
            "2  1005  Alabama, Barbour 2020-02-28            0.0           0.0   \n",
            "3  1007     Alabama, Bibb 2020-02-28            0.0           0.0   \n",
            "4  1009   Alabama, Blount 2020-02-28            0.0           0.0   \n",
            "\n",
            "   VaccinationFull  SocialDist  \n",
            "0              NaN       1.000  \n",
            "1              NaN       1.000  \n",
            "2              NaN       0.825  \n",
            "3              NaN       1.000  \n",
            "4              NaN       1.000  \n",
            "Merging all features\n",
            "Total merged data shape (2545020, 11)\n",
            "Missing percentage in total data\n",
            "VaccinationFull    35.68\n",
            "FIPS                0.00\n",
            "AgeDist             0.00\n",
            "AirPollution        0.00\n",
            "HealthDisp          0.00\n",
            "Name                0.00\n",
            "Date                0.00\n",
            "DiseaseSpread       0.00\n",
            "Transmission        0.00\n",
            "SocialDist          0.00\n",
            "Cases               0.00\n",
            "dtype: float64\n",
            "Filling null values with 0\n"
          ]
        }
      ],
      "source": [
        "# get merger class\n",
        "dataMerger = DataMerger(config, args.dataPath, args.supportPath)\n",
        "\n",
        "# if you have already created the total df one, and now just want to \n",
        "# reuse it to create different population or rurality cut\n",
        "if args.cachePath:\n",
        "    total_df = pd.read_csv(args.cachePath)\n",
        "else:\n",
        "    total_df = dataMerger.get_all_features()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL9QSxIv9Hom",
        "outputId": "2181bd9c-693d-4f95-dca7-be88bc40f7c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing total data to ../2022_May/Total.csv\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output_path_total = os.path.join(args.outputPath, 'Total.csv') \n",
        "print(f'Writing total data to {output_path_total}\\n')\n",
        "total_df.round(4).to_csv(output_path_total, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhODH1w89Hom",
        "outputId": "680d4048-4f5e-443b-d3ee-219aebcb7f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updating config file\n",
            "static locs: [0, 1, 2]\n",
            "future locs: [7, 8, 9, 10, 11, 12, 13, 14]\n",
            "target loc: 15. total input 16\n",
            "col_mappings: Static ['AgeDist', 'AirPollution', 'HealthDisp']\n",
            "col_mappings: Future ['LinearSpace', 'Constant', 'LinearTime', 'P2Time', 'P3Time', 'P4Time', 'CosWeekly', 'SinWeekly']\n",
            "col_mappings: Known Regular  ['AgeDist', 'AirPollution', 'HealthDisp', 'DiseaseSpread', 'Transmission', 'VaccinationFull', 'SocialDist']\n"
          ]
        }
      ],
      "source": [
        "print('Updating config file')\n",
        "dataMerger.update_config(args.configPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-VF9mlz9Hon"
      },
      "source": [
        "## Rurality cut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAIzVVvS9Hon",
        "outputId": "10bb2b07-326b-4c5e-94c9-a834f23569eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lost number of locations from median cut 3039\n",
            "Remaining number of locations from median cut 182\n",
            "Lost Num Locations from MAD Cut 103\n",
            "Remaining Num Locations from MAD Cut 79\n",
            "##################################################\n",
            "Final Location Count: 79\n",
            "Rurality cut dataset shape (63990, 20)\n",
            "Writing rurality cut data to ../2022_May/Rurality_cut.csv\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# can be used as cache to perform different rurality or population cuts\n",
        "# total_df = pd.read_csv(output_path_total)\n",
        "\n",
        "# you can define \"Rurality cut\" in 'data'->'support'\n",
        "# \"Rurality cut\" has to be set true. and also set lower and upper limit in RuralityRange and/or MADRange\n",
        "# having -1 in either of these two will result in ignoring that key\n",
        "if dataMerger.need_rurality_cut():\n",
        "    rurality_df = dataMerger.rurality_cut(total_df)\n",
        "\n",
        "    output_path_rurality_cut = os.path.join(args.outputPath, 'Rurality_cut.csv')\n",
        "    print(f'Writing rurality cut data to {output_path_rurality_cut}\\n')\n",
        "    rurality_df.round(4).to_csv(output_path_rurality_cut, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGPpSPbM9Hoo"
      },
      "source": [
        "## Population cut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xiq0UbD9Hoo",
        "outputId": "22d626ea-bde1-4cf9-aa54-47ae3f217a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Slicing based on top 100 counties by population\n",
            "Writing population cut data to ../2022_May/Population_cut.csv\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# you can define 'Population cut' in 'data'->'support'\n",
        "# this means how many of top counties you want to keep\n",
        "if dataMerger.need_population_cut():\n",
        "    top_df = dataMerger.population_cut(total_df)\n",
        "\n",
        "    output_path_population_cut = os.path.join(args.outputPath, 'Population_cut.csv')\n",
        "    print(f'Writing population cut data to {output_path_population_cut}\\n')\n",
        "    top_df.round(4).to_csv(output_path_population_cut, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Data preparation.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "f82c0d4b75d1a522b549257adf6e3ea321f1ee050a595ab76efcf522f2572b2a"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
