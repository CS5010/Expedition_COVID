{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This file converts the cleaned raw dataset into a single merged file that the TFTModel can work on. The work here is done following [`prepareData_Main.py`](../TF2/TFTTF2_ModelDev/prepareData_main.py) and [`data_preparation.py`](../TF2/TFTTF2_ModelDev/data_preparation.py) scripts. However, those two scripts are for the `old dataset`.\n",
    "\n",
    "If you need to change the input feature set, only add that info in the `\"data\"` section of the `config.json`. This notebook will update the rest (at least feature column mappings and locations) . If you have pivoted dynamic feature and need to melt that date columns, make sure to keep the feature name as string in `\"dynamic_features_map\"`. If it is already melted and your dynamic file has a `Date` column list or string format both is fine.\n",
    "\n",
    "In the final output all null values are replaced with 0. If you don't want that, comment that out.\n",
    "\n",
    "### Differences from the old script\n",
    "\n",
    "|Old script|This notebook|\n",
    "|---|---|\n",
    "|Can only keep one feature per static feature file.|Can keep as many features needed per static feature file.|\n",
    "|One feature per dynamic feature file. | Can handle one or multiple dynamic features per file. |\n",
    "|Converts static features into dynamic (adds date) then agains drops the dates later|No need to add dates in static features or convert it to dynamic.|\n",
    "| Left joins features based on `Date` and `FIPS`. However, this may create different merged files depending on the order of input feature files. So even with same feature files we might get very different merged files.| Outer joins features based on `Date` and inner join on `FIPS`. This fixes being dependent on processing sequence like `left` join.| \n",
    "| Uses `Population.csv` file as a base for `FIPS`. | Same |\n",
    "| Uses a random first csv file as a base for county `Name`s. Uses `Name` as id in config. | Uses `Population.csv` file as a base for `County` names. Uses `County` as id. Since `Name` would have ambiguous meaning.|\n",
    "| Re-implements custom MinMaxScaler. | Uses a MinMaxScaler from sklearn library. |\n",
    "| Scales down only the cluster choosen by Rurality. Local scaling. More like `RMSE` of their deviation ratio from the minimum value for that particular cluster. | Same. But probably will change to global scaling later. As that is generally used in practice and will make scores across different clusters dirrectly comparable. Also I am in support of not scaling the target feature to find the actual `RMSE` of covid cases.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os, json\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_date(date):\n",
    "    try:\n",
    "        pd.to_datetime(date)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def read_feature_file(file_name):\n",
    "    df = pd.read_csv(os.path.join(dataPath, f'{file_name}'))\n",
    "    # drop empty column names in the feature file\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    return df\n",
    "\n",
    "def convert_cumulative_to_daily(df):\n",
    "    date_columns = [col for col in df.columns if valid_date(col)]\n",
    "    df_advanced = df[date_columns].shift(periods=1, axis=1, fill_value=0)\n",
    "    df[date_columns] -= df_advanced[date_columns]\n",
    "    return df\n",
    "\n",
    "def missing_percentage(df):\n",
    "    return df.isnull().mean().round(4).mul(100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings(data):\n",
    "    def LinearLocationEncoding(TotalLoc):\n",
    "        linear = np.empty(TotalLoc, dtype=float)\n",
    "        for i in range(0, TotalLoc):\n",
    "            linear[i] = float(i) / float(TotalLoc)\n",
    "        return linear\n",
    "\n",
    "    def LinearTimeEncoding(Dateslisted):\n",
    "        Firstdate = Dateslisted[0]\n",
    "        numtofind = len(Dateslisted)\n",
    "        dayrange = (Dateslisted[numtofind - 1] - Firstdate).days + 1\n",
    "        linear = np.empty(numtofind, dtype=float)\n",
    "        for i in range(0, numtofind):\n",
    "            linear[i] = float((Dateslisted[i] - Firstdate).days) / float(dayrange)\n",
    "        return linear\n",
    "\n",
    "    def P2TimeEncoding(numtofind):\n",
    "        P2 = np.empty(numtofind, dtype=float)\n",
    "        for i in range(0, numtofind):\n",
    "            x = -1 + 2.0 * i / (numtofind - 1)\n",
    "            P2[i] = 0.5 * (3 * x * x - 1)\n",
    "        return P2\n",
    "\n",
    "    def P3TimeEncoding(numtofind):\n",
    "        P3 = np.empty(numtofind, dtype=float)\n",
    "        for i in range(0, numtofind):\n",
    "            x = -1 + 2.0 * i / (numtofind - 1)\n",
    "            P3[i] = 0.5 * (5 * x * x - 3) * x\n",
    "        return P3\n",
    "\n",
    "    def P4TimeEncoding(numtofind):\n",
    "        P4 = np.empty(numtofind, dtype=float)\n",
    "        for i in range(0, numtofind):\n",
    "            x = -1 + 2.0 * i / (numtofind - 1)\n",
    "            P4[i] = 0.125 * (35 * x * x * x * x - 30 * x * x + 3)\n",
    "        return P4\n",
    "\n",
    "    def WeeklyTimeEncoding(Dateslisted):\n",
    "        numtofind = len(Dateslisted)\n",
    "        costheta = np.empty(numtofind, dtype=float)\n",
    "        sintheta = np.empty(numtofind, dtype=float)\n",
    "        for i in range(0, numtofind):\n",
    "            j = Dateslisted[i].date().weekday()\n",
    "            theta = float(j) * 2.0 * math.pi / 7.0\n",
    "            costheta[i] = math.cos(theta)\n",
    "            sintheta[i] = math.sin(theta)\n",
    "        return costheta, sintheta\n",
    "\n",
    "    # Set up linear location encoding for all of the data\n",
    "    LLE = LinearLocationEncoding(config[\"support\"][\"Nloc\"])\n",
    "\n",
    "    for idx, i in enumerate(data['FIPS'].unique()):\n",
    "        data.loc[data['FIPS'] == i, 'LinearSpace'] = LLE[idx]\n",
    "\n",
    "    # Set up constant encoding\n",
    "    data['Constant'] = 0.5\n",
    "\n",
    "    # Set up linear time encoding\n",
    "    dates = pd.to_datetime(data['Date'].unique())\n",
    "\n",
    "    LTE = LinearTimeEncoding(dates)\n",
    "    P2E = P2TimeEncoding(len(dates))\n",
    "    P3E = P3TimeEncoding(len(dates))\n",
    "    P4E = P4TimeEncoding(len(dates))\n",
    "\n",
    "    CosWeeklyTE, SinWeeklyTE = WeeklyTimeEncoding(dates)\n",
    "\n",
    "    for idx, i in enumerate(dates):\n",
    "        data.loc[data['Date'] == i, 'LinearTime'] = LTE[idx]\n",
    "        data.loc[data['Date'] == i, 'P2Time'] = P2E[idx]\n",
    "        data.loc[data['Date'] == i, 'P3Time'] = P3E[idx]\n",
    "        data.loc[data['Date'] == i, 'P4Time'] = P4E[idx]\n",
    "        data.loc[data['Date'] == i, 'CosWeekly'] = CosWeeklyTE[idx]\n",
    "        data.loc[data['Date'] == i, 'SinWeekly'] = SinWeeklyTE[idx]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "If running on colab add root to both dataPath and configPath. Note that this config.json is different from the config.json in TF2 folder as that is for the old dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder where the cleaned feature file are at\n",
    "# dataPath = '../../dataset_raw/CovidDecember12-2021'\n",
    "dataPath = '../../dataset_raw/CovidMay17-2022'\n",
    "support_path = '../../dataset_raw/Support files'\n",
    "output_folder = '2022_May/'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "configPath = output_folder + 'config.json'\n",
    "with open(configPath) as inputFile:\n",
    "    config = json.load(inputFile)\n",
    "    inputFile.close()\n",
    "\n",
    "config = config['TFTparams']['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "Creates two files\n",
    "* outputPathTotal\n",
    "  * path where the merged csv files will be dumped\n",
    "  * contains all counties\n",
    "  * can be reused to create further clusters\n",
    "\n",
    "* outputPathFinal\n",
    "  * only contains counties selected by current Rurality cut in config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_total = output_folder + 'Total.csv'\n",
    "output_top500 = output_folder + 'Top_500.csv'\n",
    "output_rurality_cut = output_folder + 'Rurality_cut.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static features\n",
    "## Static features mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static features ['AgeDist', 'AirPollution', 'HealthDisp']\n"
     ]
    }
   ],
   "source": [
    "# map between csv filename and feature columns extracted from that file\n",
    "# each file must have FIPS column, no index\n",
    "static_features_map = config['static_features_map']\n",
    "static_features = []\n",
    "for value in static_features_map.values():\n",
    "    if type(value)==list:\n",
    "        static_features.extend(value)\n",
    "    else:\n",
    "        static_features.append(value)\n",
    "\n",
    "print(f'Static features {static_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read base static feature\n",
    "All other static features will be merged on this. County names are also extracted from this base feature file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique counties present 3142\n"
     ]
    }
   ],
   "source": [
    "# We'll use population file as the base and take the county names from it\n",
    "# then merge other files to it\n",
    "\n",
    "support_file = config['support']['Population']\n",
    "population = pd.read_csv(os.path.join(support_path, f'{support_file}'))\n",
    "\n",
    "id_columns = ['FIPS']\n",
    "# population.rename({'COUNTY':'County'}, axis=1, inplace=True)\n",
    "static_df = population[id_columns]\n",
    "\n",
    "locs = static_df['FIPS'].nunique()\n",
    "print(f'Unique counties present {locs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging feature Age Distribution.csv with length 3142\n",
      "Merging feature Air Pollution.csv with length 3142\n",
      "Merging feature Health Disparities.csv with length 3142\n",
      "\n",
      "Merged static features have 3142 counties\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>AgeDist</th>\n",
       "      <th>AirPollution</th>\n",
       "      <th>HealthDisp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.2606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>0.4371</td>\n",
       "      <td>0.2039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>0.5797</td>\n",
       "      <td>0.5090</td>\n",
       "      <td>0.6562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>0.5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>0.5755</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.4462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS  AgeDist  AirPollution  HealthDisp\n",
       "0  1001   0.5017        0.5210      0.2606\n",
       "1  1003   0.6095        0.4371      0.2039\n",
       "2  1005   0.5797        0.5090      0.6562\n",
       "3  1007   0.5427        0.4910      0.5320\n",
       "4  1009   0.5755        0.5210      0.4462"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file_name in static_features_map.keys():\n",
    "    if file_name == support_file: continue\n",
    "\n",
    "    feature_df = read_feature_file(file_name)\n",
    "    print(f'Merging feature {file_name} with length {feature_df.shape[0]}')\n",
    "\n",
    "    has_date_columns = False\n",
    "    for column in feature_df.columns:\n",
    "        if valid_date(column):\n",
    "            has_date_columns = True\n",
    "            break\n",
    "\n",
    "    # if static feature has date column, convert the first date column into feature of that name\n",
    "    # this is for PVI data, and in that case static_features_map[file_name] is a single value\n",
    "    if has_date_columns:\n",
    "        feature_column = static_features_map[file_name]\n",
    "        feature_df.rename({column: feature_column}, axis=1, inplace=True)\n",
    "        feature_df = feature_df[['FIPS', feature_column]]\n",
    "    else: \n",
    "        feature_columns = static_features_map[file_name]\n",
    "        if type(feature_columns) == list:\n",
    "            feature_df = feature_df[['FIPS'] + feature_columns]\n",
    "        else:\n",
    "            feature_df = feature_df[['FIPS', feature_columns]]\n",
    "\n",
    "    static_df = static_df.merge(feature_df, how='inner', on='FIPS')\n",
    "\n",
    "print(f\"\\nMerged static features have {static_df['FIPS'].nunique()} counties\")\n",
    "static_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic features\n",
    "## Dynamic feature mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DiseaseSpread', 'Transmission', 'VaccinationFull', 'SocialDist']\n"
     ]
    }
   ],
   "source": [
    "# notice: no need to add .csv to filename\n",
    "# {feature_file_name: feature_name}\n",
    "dynamic_features_map = config['dynamic_features_map']\n",
    "\n",
    "dynamic_features = []\n",
    "for value in dynamic_features_map.values():\n",
    "    if type(value)==list:\n",
    "        dynamic_features.extend(value)\n",
    "    else:\n",
    "        dynamic_features.append(value)\n",
    "print(dynamic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = pd.to_datetime(config['support']['FirstDate'])\n",
    "last_date = pd.to_datetime(config['support']['LastDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Disease Spread.csv\n",
      "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
      "Length 2545020.\n",
      "Reading Transmissible Cases.csv\n",
      "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
      "Length 2545020.\n",
      "Reading Vaccination.csv\n",
      "Min date 2020-12-13 00:00:00, max date 2022-05-17 00:00:00\n",
      "Length 1679704.\n",
      "Reading Social Distancing.csv\n",
      "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
      "Length 2545020.\n",
      "Total dynamic feature shape (2587742, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>DiseaseSpread</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>VaccinationFull</th>\n",
       "      <th>SocialDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>Alabama, Baldwin</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama, Barbour</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>Alabama, Bibb</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>Alabama, Blount</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS              Name       Date  DiseaseSpread  Transmission  \\\n",
       "0  1001  Alabama, Autauga 2020-02-28            0.0           0.0   \n",
       "1  1003  Alabama, Baldwin 2020-02-28            0.0           0.0   \n",
       "2  1005  Alabama, Barbour 2020-02-28            0.0           0.0   \n",
       "3  1007     Alabama, Bibb 2020-02-28            0.0           0.0   \n",
       "4  1009   Alabama, Blount 2020-02-28            0.0           0.0   \n",
       "\n",
       "   VaccinationFull  SocialDist  \n",
       "0              NaN       1.000  \n",
       "1              NaN       1.000  \n",
       "2              NaN       0.825  \n",
       "3              NaN       1.000  \n",
       "4              NaN       1.000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_df = None\n",
    "merge_keys = ['FIPS', 'Date']\n",
    "\n",
    "for file_name in dynamic_features_map.keys():\n",
    "    print(f'Reading {file_name}')\n",
    "    df = read_feature_file(file_name)\n",
    "    \n",
    "    # check whether the Date column has been pivoted\n",
    "    if 'Date' not in df.columns:\n",
    "         # technically this should be set of common columns\n",
    "        id_vars = [col for col in df.columns if not valid_date(col)]\n",
    "        df = df.melt(\n",
    "            id_vars= id_vars,\n",
    "            var_name='Date', value_name=dynamic_features_map[file_name]\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "    # can be needed as some feature files may have different date format\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    print(f'Min date {df[\"Date\"].min()}, max date {df[\"Date\"].max()}')\n",
    "    df = df[(df['Date'] >= first_date) & (df['Date'] <= last_date)]\n",
    "\n",
    "    print(f'Length {df.shape[0]}.')\n",
    "\n",
    "    if dynamic_df is None: dynamic_df = df\n",
    "    else:\n",
    "        # if a single file has multiple features\n",
    "        if type(dynamic_features_map[file_name]) == list:\n",
    "            selected_columns = merge_keys + dynamic_features_map[file_name]\n",
    "        else:\n",
    "            selected_columns = merge_keys + [dynamic_features_map[file_name]]\n",
    "\n",
    "        # using outer to keep the union of dates \n",
    "        # as vaccination dates are not available before late in 2020\n",
    "        dynamic_df = dynamic_df.merge(df[selected_columns], how='outer',on=merge_keys)\n",
    "\n",
    "        # however, we don't need to keep mismatch of FIPS\n",
    "        dynamic_df = dynamic_df[~dynamic_df['FIPS'].isna()]\n",
    "\n",
    "print(f'Total dynamic feature shape {dynamic_df.shape}')\n",
    "dynamic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target feature\n",
    "Converts cumulative covid cases into daily cases. Also remove outliers. For now only handling one target here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>2020-01-22</th>\n",
       "      <th>2020-01-23</th>\n",
       "      <th>2020-01-24</th>\n",
       "      <th>2020-01-25</th>\n",
       "      <th>2020-01-26</th>\n",
       "      <th>2020-01-27</th>\n",
       "      <th>2020-01-28</th>\n",
       "      <th>2020-01-29</th>\n",
       "      <th>2020-01-30</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-05-16</th>\n",
       "      <th>2022-05-17</th>\n",
       "      <th>2022-05-18</th>\n",
       "      <th>2022-05-19</th>\n",
       "      <th>2022-05-20</th>\n",
       "      <th>2022-05-21</th>\n",
       "      <th>2022-05-22</th>\n",
       "      <th>2022-05-23</th>\n",
       "      <th>2022-05-24</th>\n",
       "      <th>2022-05-25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 856 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS  2020-01-22  2020-01-23  2020-01-24  2020-01-25  2020-01-26  \\\n",
       "0  1001           0           0           0           0           0   \n",
       "1  1003           0           0           0           0           0   \n",
       "2  1005           0           0           0           0           0   \n",
       "3  1007           0           0           0           0           0   \n",
       "4  1009           0           0           0           0           0   \n",
       "\n",
       "   2020-01-27  2020-01-28  2020-01-29  2020-01-30  ...  2022-05-16  \\\n",
       "0           0           0           0           0  ...           7   \n",
       "1           0           0           0           0  ...          54   \n",
       "2           0           0           0           0  ...           7   \n",
       "3           0           0           0           0  ...           6   \n",
       "4           0           0           0           0  ...          10   \n",
       "\n",
       "   2022-05-17  2022-05-18  2022-05-19  2022-05-20  2022-05-21  2022-05-22  \\\n",
       "0           1           2          12           6           0           0   \n",
       "1          25          19          36          35           0           0   \n",
       "2           0           3           0           1           0           0   \n",
       "3           2           1           2           1           0           0   \n",
       "4           4           6           6           8           0           0   \n",
       "\n",
       "   2022-05-23  2022-05-24  2022-05-25  \n",
       "0          13           0          12  \n",
       "1         103           0          88  \n",
       "2           2           0           0  \n",
       "3           4           0           6  \n",
       "4           6           0           7  \n",
       "\n",
       "[5 rows x 856 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cases\n",
    "target_column = list(config['targets'].keys())[0]\n",
    "\n",
    "# read cumulative cases.csv\n",
    "target_df = read_feature_file(config['targets'][target_column])\n",
    "\n",
    "if 'Date' not in target_df.columns:\n",
    "    target_df = convert_cumulative_to_daily(target_df)\n",
    "    target_df.fillna(0, inplace=True)\n",
    "\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = target_df.melt(\n",
    "    id_vars= ['FIPS'],\n",
    "    var_name='Date', value_name='Cases'\n",
    ").reset_index(drop=True)\n",
    "target_df = target_df.fillna(0)\n",
    "target_df['Date'] = pd.to_datetime(target_df['Date'])\n",
    "\n",
    "# some days had old covid cases fixed by adding neg values\n",
    "target_df.loc[target_df['Cases']<0, 'Cases'] = 0\n",
    "\n",
    "target_df = target_df[(target_df['Date'] >= first_date) & (target_df['Date'] <= last_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2545020, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>AgeDist</th>\n",
       "      <th>AirPollution</th>\n",
       "      <th>HealthDisp</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>DiseaseSpread</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>VaccinationFull</th>\n",
       "      <th>SocialDist</th>\n",
       "      <th>Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS  AgeDist  AirPollution  HealthDisp              Name       Date  \\\n",
       "0  1001   0.5017         0.521      0.2606  Alabama, Autauga 2020-02-28   \n",
       "1  1001   0.5017         0.521      0.2606  Alabama, Autauga 2020-02-29   \n",
       "2  1001   0.5017         0.521      0.2606  Alabama, Autauga 2020-03-01   \n",
       "3  1001   0.5017         0.521      0.2606  Alabama, Autauga 2020-03-02   \n",
       "4  1001   0.5017         0.521      0.2606  Alabama, Autauga 2020-03-03   \n",
       "\n",
       "   DiseaseSpread  Transmission  VaccinationFull  SocialDist  Cases  \n",
       "0            0.0           0.0              NaN         1.0    0.0  \n",
       "1            0.0           0.0              NaN         1.0    0.0  \n",
       "2            0.0           0.0              NaN         1.0    0.0  \n",
       "3            0.0           0.0              NaN         1.0    0.0  \n",
       "4            0.0           0.0              NaN         1.0    0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the joint types should be inner for consistency\n",
    "total_df = dynamic_df.merge(target_df, how='outer', on=['FIPS', 'Date'])\n",
    "total_df = static_df.merge(total_df, how='inner', on='FIPS')\n",
    "total_df = total_df.reset_index(drop=True)\n",
    "\n",
    "print(total_df.shape)\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VaccinationFull    35.68\n",
       "FIPS                0.00\n",
       "AgeDist             0.00\n",
       "AirPollution        0.00\n",
       "HealthDisp          0.00\n",
       "Name                0.00\n",
       "Date                0.00\n",
       "DiseaseSpread       0.00\n",
       "Transmission        0.00\n",
       "SocialDist          0.00\n",
       "Cases               0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2545020, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>AgeDist</th>\n",
       "      <th>AirPollution</th>\n",
       "      <th>HealthDisp</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>DiseaseSpread</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>VaccinationFull</th>\n",
       "      <th>SocialDist</th>\n",
       "      <th>Cases</th>\n",
       "      <th>TimeFromStart</th>\n",
       "      <th>LinearSpace</th>\n",
       "      <th>Constant</th>\n",
       "      <th>LinearTime</th>\n",
       "      <th>P2Time</th>\n",
       "      <th>P3Time</th>\n",
       "      <th>P4Time</th>\n",
       "      <th>CosWeekly</th>\n",
       "      <th>SinWeekly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.433884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>-0.985213</td>\n",
       "      <td>0.975415</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.974928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.985204</td>\n",
       "      <td>-0.970517</td>\n",
       "      <td>0.951104</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-0.781831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.977833</td>\n",
       "      <td>-0.955912</td>\n",
       "      <td>0.927065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>Alabama, Autauga</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.970480</td>\n",
       "      <td>-0.941398</td>\n",
       "      <td>0.903296</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.781831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS  AgeDist  AirPollution  HealthDisp              Name       Date  \\\n",
       "0  1001   0.5017         0.521      0.2606  Alabama, Autauga 2020-02-28   \n",
       "1  1001   0.5017         0.521      0.2606  Alabama, Autauga 2020-02-29   \n",
       "2  1001   0.5017         0.521      0.2606  Alabama, Autauga 2020-03-01   \n",
       "3  1001   0.5017         0.521      0.2606  Alabama, Autauga 2020-03-02   \n",
       "4  1001   0.5017         0.521      0.2606  Alabama, Autauga 2020-03-03   \n",
       "\n",
       "   DiseaseSpread  Transmission  VaccinationFull  SocialDist  Cases  \\\n",
       "0            0.0           0.0              0.0         1.0    0.0   \n",
       "1            0.0           0.0              0.0         1.0    0.0   \n",
       "2            0.0           0.0              0.0         1.0    0.0   \n",
       "3            0.0           0.0              0.0         1.0    0.0   \n",
       "4            0.0           0.0              0.0         1.0    0.0   \n",
       "\n",
       "   TimeFromStart  LinearSpace  Constant  LinearTime    P2Time    P3Time  \\\n",
       "0              0          0.0       0.5    0.000000  1.000000 -1.000000   \n",
       "1              1          0.0       0.5    0.001235  0.992593 -0.985213   \n",
       "2              2          0.0       0.5    0.002469  0.985204 -0.970517   \n",
       "3              3          0.0       0.5    0.003704  0.977833 -0.955912   \n",
       "4              4          0.0       0.5    0.004938  0.970480 -0.941398   \n",
       "\n",
       "     P4Time  CosWeekly  SinWeekly  \n",
       "0  1.000000  -0.900969  -0.433884  \n",
       "1  0.975415  -0.222521  -0.974928  \n",
       "2  0.951104   0.623490  -0.781831  \n",
       "3  0.927065   1.000000   0.000000  \n",
       "4  0.903296   0.623490   0.781831  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df['TimeFromStart'] = (total_df['Date'] - total_df['Date'].min()).dt.days\n",
    "\n",
    "pre_columns = total_df.columns\n",
    "total_df = add_embeddings(total_df)\n",
    "known_future_features = [col for col in total_df.columns if col not in pre_columns]\n",
    "\n",
    "print(total_df.shape)\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint the total merged data\n",
    "total_df.round(4).to_csv(output_total, index=False)\n",
    "\n",
    "# Uncomment if only starting from here\n",
    "# total_df = pd.read_csv(outputPathTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rurality median based cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost number of locations from median cut 3039\n",
      "Remaining number of locations from median cut 182\n",
      "Lost Num Locations from MAD Cut 103\n",
      "Remaining Num Locations from MAD Cut 79\n",
      "##################################################\n",
      "Final Location Count: 79\n"
     ]
    }
   ],
   "source": [
    "MADRANGE = config['support']['MADRange']\n",
    "RURRANGE = config['support']['RuralityRange']\n",
    "\n",
    "# fails to read on unicode\n",
    "rur = pd.read_csv(os.path.join(support_path, config['support'][\"Rurality\"]), encoding = 'latin1')\n",
    "\n",
    "locs = rur.FIPS\n",
    "\n",
    "if -1 in RURRANGE:\n",
    "    print('No Median Rurality Cut')\n",
    "    lost = []\n",
    "else:\n",
    "    locs = rur[(rur['Median'] >= RURRANGE[0]) & (rur['Median'] <= RURRANGE[1])].FIPS\n",
    "    lost = rur[~((rur['Median'] >= RURRANGE[0]) & (rur['Median'] <= RURRANGE[1]))].FIPS\n",
    "    rur = rur[rur['FIPS'].isin(locs)]\n",
    "\n",
    "print('Lost number of locations from median cut ' + str(len(lost)))\n",
    "print('Remaining number of locations from median cut ' + str(len(locs)))\n",
    "\n",
    "if -1 in MADRANGE:\n",
    "    print('No MAD cut')\n",
    "    lost = []\n",
    "else:\n",
    "    locs = rur[(rur['MAD'] >= MADRANGE[0]) & (rur['MAD'] < MADRANGE[1])].FIPS\n",
    "    lost = rur[~((rur['MAD'] >= MADRANGE[0]) & (rur['MAD'] < MADRANGE[1]))].FIPS\n",
    "\n",
    "print('Lost Num Locations from MAD Cut ' + str(len(lost)))\n",
    "print('Remaining Num Locations from MAD Cut ' + str(len(locs)))\n",
    "\n",
    "print('#' * 50)\n",
    "print('Final Location Count: ' + str(len(locs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63990, 20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the selected counties\n",
    "df = total_df[total_df['FIPS'].isin(locs)].reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.round(4).to_csv(output_rurality_cut, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 500 counties by population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_fips = population.sort_values(by=['POPESTIMATE2019'], ascending=False)['FIPS'].values\n",
    "df = total_df[total_df['FIPS'].isin(sorted_fips[:500])]\n",
    "df.round(4).to_csv(output_top500, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 counties by population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = total_df[total_df['FIPS'].isin(sorted_fips[:100])]\n",
    "df.round(4).to_csv(output_folder + 'Top_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update config.json\n",
    "Make sure your config.json is consistent with these info. Maybe we can directly update config from this notebook or create a separate config for model in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static locs: [0, 1, 2]\n",
      "future locs: [7, 8, 9, 10, 11, 12, 13, 14]\n",
      "target loc: 15. total input 16\n",
      "col_mappings: Static ['AgeDist', 'AirPollution', 'HealthDisp']\n",
      "col_mappings: Future ['LinearSpace', 'Constant', 'LinearTime', 'P2Time', 'P3Time', 'P4Time', 'CosWeekly', 'SinWeekly']\n",
      "col_mappings: Known Regular  ['AgeDist', 'AirPollution', 'HealthDisp', 'DiseaseSpread', 'Transmission', 'VaccinationFull', 'SocialDist']\n"
     ]
    }
   ],
   "source": [
    "static_locs = [i for i in range(len(static_features))]\n",
    "print(f'static locs: {static_locs}')\n",
    "\n",
    "start = len(static_features) + len(dynamic_features)\n",
    "future_locs = [i for i in range(start, start + len(known_future_features))]\n",
    "print(f'future locs: {future_locs}')\n",
    "\n",
    "target_loc = start + len(known_future_features)\n",
    "print(f'target loc: {target_loc}. total input {target_loc+1}')\n",
    "\n",
    "print(f'col_mappings: Static {static_features}')\n",
    "print(f'col_mappings: Future {known_future_features}')\n",
    "print(f'col_mappings: Known Regular  {static_features + dynamic_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the config file again\n",
    "with open(configPath) as inputFile:\n",
    "    config = json.load(inputFile)\n",
    "    inputFile.close()\n",
    "\n",
    "config[\"TFTparams\"][\"static_locs\"] = static_locs\n",
    "config[\"TFTparams\"][\"future_locs\"] = future_locs\n",
    "config[\"TFTparams\"][\"target_loc\"] = [target_loc]\n",
    "config[\"TFTparams\"][\"total_inputs\"] = target_loc + 1\n",
    "\n",
    "config[\"TFTparams\"][\"col_mappings\"][\"Static\"] = static_features\n",
    "\n",
    "# this notebook doesn't support multiple target columns yet\n",
    "config[\"TFTparams\"][\"col_mappings\"][\"Target\"] = [target_column]\n",
    "config[\"TFTparams\"][\"col_mappings\"][\"Future\"] = known_future_features\n",
    "config[\"TFTparams\"][\"col_mappings\"][\"Known Regular\"] = static_features + dynamic_features\n",
    "\n",
    "# dump the json config\n",
    "with open(configPath, 'w') as outputFile:\n",
    "    json.dump(config, outputFile, indent=4)\n",
    "    outputFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run TFT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go to `TF2/TFTTF2_ModelDev` and run the following to run TFT on this new dataset\n",
    "\n",
    "```python\n",
    "python main.py -p \"../../dataset_new/config.json\" -c checkpoints -d \"../../dataset_new/TFTdfCurrent.csv\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f82c0d4b75d1a522b549257adf6e3ea321f1ee050a595ab76efcf522f2572b2a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
