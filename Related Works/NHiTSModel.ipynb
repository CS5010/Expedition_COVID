{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# disable chained assignments\n",
    "pd.options.mode.chained_assignment = None \n",
    "import os, gc\n",
    "from darts import TimeSeries\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning import seed_everything\n",
    "from datetime import datetime\n",
    "\n",
    "# this stops pytorch from logging GPU info each time your model predicts something\n",
    "# https://github.com/Lightning-AI/lightning/issues/3431\n",
    "import logging\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
    "\n",
    "# for some warning bugs from darts\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "from splits import *\n",
    "from plotter import *\n",
    "\n",
    "SHOW_IMAGE = True\n",
    "VERBOSE = True\n",
    "Split = Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Result folder\n",
    "output_folder = 'results_NHiTS'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    static_features = ['AgeDist', 'HealthDisp']\n",
    "    past_features = ['DiseaseSpread', 'Transmission', 'VaccinationFull', 'SocialDist']\n",
    "    known_future = ['SinWeekly', 'CosWeekly']\n",
    "    time_index = 'TimeFromStart' # note that this is an index feature commonly used by all timeseries models\n",
    "\n",
    "    features =  static_features + past_features + known_future\n",
    "    targets = ['Cases']\n",
    "    group_id = 'FIPS'\n",
    "    selected_columns = features + targets\n",
    "    input_sequence_length = 13\n",
    "    output_sequence_length = 15\n",
    "    batch_size = 128\n",
    "    epochs = 4\n",
    "    learning_rate = 1e-3\n",
    "    early_stopping_patience = 5\n",
    "    seed = 7\n",
    "\n",
    "seed_everything(Config.seed)\n",
    "targets = Config.targets\n",
    "group_id = Config.group_id\n",
    "time_index = Config.time_index\n",
    "input_sequence_length = Config.input_sequence_length\n",
    "output_sequence_length = Config.output_sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../TFT-pytorch/2022_May_cleaned/Top_100.csv')\n",
    "df['Date'] = to_datetime(df['Date'])\n",
    "df[time_index] = df[time_index].astype(int)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_data(df, Split, input_sequence_length)\n",
    "train_df, val_df, test_df, feature_scaler, target_scaler = scale_data(\n",
    "    train_df, val_df, test_df, Config.features, targets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import round, mean, float32\n",
    "\n",
    "def get_covariates(df:pd.DataFrame, tail_cut=False):\n",
    "    if tail_cut:\n",
    "        cutoff = df[time_index].max() - output_sequence_length + 1\n",
    "        df = df[df[time_index]<cutoff]\n",
    "\n",
    "    series = TimeSeries.from_group_dataframe(\n",
    "        df, time_col=time_index, group_cols=group_id,\n",
    "        static_cols=Config.static_features, value_cols=targets,\n",
    "    )\n",
    "    past_covariates = TimeSeries.from_group_dataframe(\n",
    "        df, group_cols=group_id,\n",
    "        time_col = time_index, value_cols=Config.past_features\n",
    "    )\n",
    "\n",
    "    # timeseries has default precision float64, this doesn't match \n",
    "    # with pl trainer which has precision float32\n",
    "    for covariates in [series, past_covariates]:\n",
    "        for index in range(len(covariates)):\n",
    "            covariates[index] = covariates[index].astype(float32)\n",
    "\n",
    "    return series, past_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series, train_past_covariates = get_covariates(train_df)\n",
    "val_series, val_past_covariates = get_covariates(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import NHiTSModel\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from torch.nn.modules import MSELoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHiTSModel(\n",
    "    input_chunk_length=input_sequence_length, \n",
    "    output_chunk_length=output_sequence_length,\n",
    "    batch_size=Config.batch_size, loss_fn=MSELoss(),\n",
    "    optimizer_cls=Adam,    \n",
    "    optimizer_kwargs={'lr': Config.learning_rate}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=Config.early_stopping_patience,\n",
    "    min_delta=0\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    dirpath=output_folder, monitor=\"val_loss\", filename=\"best-{epoch}\"\n",
    ")\n",
    "\n",
    "start = datetime.now()\n",
    "print(f'\\n----Training started at {start}----\\n')\n",
    "model.fit(\n",
    "    train_series, val_series=val_series, verbose=VERBOSE,\n",
    "    past_covariates=train_past_covariates, val_past_covariates=val_past_covariates,\n",
    "    trainer = Trainer(\n",
    "        accelerator= \"auto\", max_epochs=Config.epochs,\n",
    "        callbacks=[early_stopping, checkpoint], \n",
    "        enable_progress_bar=VERBOSE, logger=False\n",
    "    )\n",
    ")\n",
    "\n",
    "gc.collect()\n",
    "end = datetime.now()\n",
    "print(f'\\n----Training ended at {end}, elapsed time {end-start}.')\n",
    "print(f'Best model by validation loss saved at {checkpoint.filepath}.')\n",
    "print(f'Loading best model.')\n",
    "model.load_weights(checkpoint.filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_forecast(\n",
    "    model, df, series_list, past_list, target_scaler\n",
    "):\n",
    "    prediction_start = df[time_index].min() + input_sequence_length\n",
    "\n",
    "    preds = []\n",
    "    # each county is a unique timeseries\n",
    "    for fips, series, past in zip(\n",
    "        df[group_id].unique(), series_list, past_list\n",
    "    ):\n",
    "\n",
    "        if len(series) > (input_sequence_length + output_sequence_length):\n",
    "            # list of predictions with sliding window\n",
    "            county_preds = model.historical_forecasts(\n",
    "                series, \n",
    "                past_covariates=past,\n",
    "                start=prediction_start,\n",
    "                retrain=False, last_points_only=False, verbose=VERBOSE,\n",
    "                forecast_horizon=output_sequence_length, stride=1,\n",
    "            )\n",
    "            # reseting index here is ok since only one time column\n",
    "            county_preds = pd.concat(\n",
    "                [pred.pd_dataframe().reset_index() for pred in county_preds], axis=0\n",
    "            )\n",
    "        else:\n",
    "            county_preds = model.predict(\n",
    "                output_sequence_length,\n",
    "                series, n_jobs=-1,\n",
    "                past_covariates=past,\n",
    "                verbose=VERBOSE\n",
    "            )\n",
    "            county_preds = county_preds.pd_dataframe().reset_index()\n",
    "\n",
    "        county_preds[group_id] = fips\n",
    "        preds.append(county_preds)\n",
    "        # if len(preds)==2:\n",
    "        #     break\n",
    "\n",
    "    # conver the predicted list to a dataframe\n",
    "    preds = pd.concat(preds, axis=0).reset_index(drop=True)\n",
    "    # scale up\n",
    "    preds[targets] = target_scaler.inverse_transform(\n",
    "        preds[targets].values\n",
    "    )\n",
    "    # round and remove negative targets since infection can't be neg\n",
    "    preds[targets] = preds[targets].apply(round)\n",
    "    for target in targets:\n",
    "        preds.loc[preds[target]<0, target] = 0\n",
    "        \n",
    "    # since this is sliding window, some cases will have multiple prediction with different forecast horizon\n",
    "    preds = preds.groupby([group_id, time_index], axis=0)[targets].aggregate(mean)\n",
    "\n",
    "    preds.rename({target:'Predicted_'+target for target in targets}, axis=1, inplace=True)\n",
    "\n",
    "    target_df = df[[group_id, time_index, 'Date'] + targets].copy().reset_index(drop=True)\n",
    "    target_df[targets] = target_scaler.inverse_transform(target_df[targets]).astype(int)\n",
    "\n",
    "    merge_keys = [group_id, time_index]\n",
    "    prediction_df = preds.merge(target_df[['Date'] + merge_keys + targets], on=merge_keys, how='inner')\n",
    "    gc.collect()\n",
    "\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTrain prediction')\n",
    "train_prediction_df = historical_forecast(\n",
    "    model, train_df, train_series, train_past_covariates, target_scaler\n",
    ")\n",
    "\n",
    "show_result(train_prediction_df, targets)\n",
    "print(train_prediction_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    plot_predition(\n",
    "        train_prediction_df, target, plot_error=True, show_image=SHOW_IMAGE,\n",
    "        figure_path=os.path.join(output_folder, f'Summed_{target}_Train.jpg')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_series, val_past_covariates = get_covariates(val_df, tail_cut=True)\n",
    "print('\\nValidation prediction')\n",
    "val_prediction_df = historical_forecast(\n",
    "    model, val_df, val_series, val_past_covariates, target_scaler\n",
    ")\n",
    "\n",
    "show_result(val_prediction_df, targets)\n",
    "print(val_prediction_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    plot_predition(\n",
    "        val_prediction_df, target, show_image=SHOW_IMAGE,\n",
    "        figure_path=os.path.join(output_folder, f'Summed_{target}_Validation.jpg')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series, test_past_covariates = get_covariates(test_df, tail_cut=True)\n",
    "print('\\nTest prediction')\n",
    "test_prediction_df = historical_forecast(\n",
    "    model, test_df, test_series, test_past_covariates, target_scaler\n",
    ")\n",
    "\n",
    "show_result(test_prediction_df, targets)\n",
    "print(test_prediction_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    plot_predition(\n",
    "        test_prediction_df, target, show_image=SHOW_IMAGE,\n",
    "        figure_path=os.path.join(output_folder, f'Summed_{target}_Test.jpg')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction_df['Split'] = 'train'\n",
    "val_prediction_df['Split'] = 'validation'\n",
    "test_prediction_df['Split'] = 'test'\n",
    "merged_df = pd.concat([train_prediction_df, val_prediction_df, test_prediction_df], axis=0)\n",
    "merged_df.drop(columns=['TimeFromStart'], inplace=True)\n",
    "\n",
    "merged_df.to_csv(os.path.join(output_folder, 'predictions.csv'), index=False)\n",
    "print(f'Ended at {datetime.now()}. Elapsed time {datetime.now() - start}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43fc5fbfa959c1c54ddf7d7acab30a2019a504b895513ba1ba722e7f395657c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
