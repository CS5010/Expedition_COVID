{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jp_MQeY9Hob"
      },
      "source": [
        "# Introduction\n",
        "This file converts the cleaned raw dataset into a single merged file that the TFTModel can work on. The script version available at [prepare_data.py](../script/prepare_data.py).\n",
        "\n",
        "If you need to change the input feature set, only add that info in the `\"data\"` section of the json configuration  file. This notebook will update the rest (at least feature column mappings and locations) . If you have pivoted dynamic feature and need to melt that date columns, make sure to keep the feature name as `string` in `\"dynamic_features_map\"`. If it is already melted and your dynamic file has a `Date` column, `list` or `string` format both is fine.\n",
        "\n",
        "In the final output all null values are replaced with 0. If you don't want that, comment that out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI10VjY39Hof"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1M2WLI7D9Hog"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append( '..' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fy3zL-09Hoh"
      },
      "source": [
        "# Setup storage\n",
        "\n",
        "You would need the `CovidMay17-2022` and `Support files` folders for the dateset. And the `TFT-pytorch` folder for the codes. Upload both of them in the place where you are running the code from. My folder structure looks like this\n",
        "* dataset_raw\n",
        "    * CovidMay17-2022\n",
        "    * Support files\n",
        "* TFT-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMX9mq7-9Hoi"
      },
      "source": [
        "## Googe drive\n",
        "Not needed, since you can run this on CPU. But set `running_on_colab = True` if using. Also update the `cd` path so that it points to the notebook folder in your drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "405O2njt9Hoi",
        "outputId": "06b68e92-5354-43ff-b93e-1e5b9502f15d"
      },
      "outputs": [],
      "source": [
        "running_on_colab = False\n",
        "\n",
        "if running_on_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    %cd /content/drive/My Drive/Projects/Covid/TFT-pytorch/notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlaIcaHc9Hoi"
      },
      "source": [
        "## Input\n",
        "If running on colab, modify the below paths accordingly. Note that this config.json is different from the config.json in TF2 folder as that is for the old dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kKXlhpDi9Hoj"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from Class.DataMerger import *\n",
        "\n",
        "@dataclass\n",
        "class args:\n",
        "    # folder where the cleaned feature file are at\n",
        "    dataPath = '../../dataset_raw/CovidMay17-2022'\n",
        "    supportPath = '../../dataset_raw/Support files'\n",
        "    configPath = '../config_2022_May.json'\n",
        "    cachePath = None # '../2022_May/Total.csv'\n",
        "\n",
        "    # choose this carefully\n",
        "    outputPath = '../2022_May_target_cleaned/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE7F4cXP9Hok",
        "outputId": "c5927406-1491-4ae3-d252-32e1f2f3f231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config file loaded from ../config_2022_May.json\n"
          ]
        }
      ],
      "source": [
        "# create output path if it doesn't exist\n",
        "if not os.path.exists(args.outputPath):\n",
        "    print(f'Creating output directory {args.outputPath}')\n",
        "    os.makedirs(args.outputPath, exist_ok=True)\n",
        "\n",
        "import json\n",
        "\n",
        "# load config file\n",
        "with open(args.configPath) as inputFile:\n",
        "    config = json.load(inputFile)\n",
        "    print(f'Config file loaded from {args.configPath}')\n",
        "    inputFile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BgfTz2F9Hol"
      },
      "source": [
        "# Data merger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VtM_7Mh9Hol"
      },
      "source": [
        "## Total features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get merger class\n",
        "dataMerger = DataMerger(config, args.dataPath, args.supportPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLrT8EfF9Hom",
        "outputId": "3a83f81f-7cc2-404e-a076-43372808dc0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique counties present 3142\n",
            "Merging feature Age Distribution.csv with length 3142\n",
            "Merging feature Health Disparities.csv with length 3142\n",
            "\n",
            "Merged static features have 3142 counties\n",
            "   FIPS  AgeDist  HealthDisp\n",
            "0  1001   0.5017      0.2606\n",
            "1  1003   0.6095      0.2039\n",
            "2  1005   0.5797      0.6562\n",
            "3  1007   0.5427      0.5320\n",
            "4  1009   0.5755      0.4462\n",
            "Will remove outliers from dynamic inputs.\n",
            "Will filter out dynamic features outside range, train start 2020-02-28 00:00:00 and test end 2022-05-17 00:00:00.\n",
            "Reading Disease Spread.csv\n",
            "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
            "Length 2545020.\n",
            "\n",
            "Reading Transmissible Cases.csv\n",
            "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
            "Length 2545020.\n",
            "\n",
            "Reading Vaccination.csv\n",
            "Min date 2020-12-13 00:00:00, max date 2022-05-17 00:00:00\n",
            "Length 1679704.\n",
            "\n",
            "Reading Social Distancing.csv\n",
            "Min date 2020-02-28 00:00:00, max date 2022-05-17 00:00:00\n",
            "Length 2545020.\n",
            "\n",
            "Total dynamic feature shape (2587742, 7)\n",
            "   FIPS              Name       Date  DiseaseSpread  Transmission  \\\n",
            "0  1001  Alabama, Autauga 2020-02-28            0.0           0.0   \n",
            "1  1003  Alabama, Baldwin 2020-02-28            0.0           0.0   \n",
            "2  1005  Alabama, Barbour 2020-02-28            0.0           0.0   \n",
            "3  1007     Alabama, Bibb 2020-02-28            0.0           0.0   \n",
            "4  1009   Alabama, Blount 2020-02-28            0.0           0.0   \n",
            "\n",
            "   VaccinationFull  SocialDist  \n",
            "0              NaN       1.000  \n",
            "1              NaN       1.000  \n",
            "2              NaN       0.825  \n",
            "3              NaN       1.000  \n",
            "4              NaN       1.000  \n",
            "Will remove outliers from target.\n",
            "Will filter out target data outside range, train start 2020-02-28 00:00:00 and test end 2022-05-17 00:00:00.\n",
            "Reading Cases.csv\n",
            "Setting negative daily Cases counts to zero.\n",
            "Min date 2020-01-22 00:00:00, max date 2022-05-25 00:00:00\n",
            "Length 2545020.\n",
            "\n",
            "Reading Deaths.csv\n",
            "Setting negative daily Deaths counts to zero.\n",
            "Min date 2020-01-22 00:00:00, max date 2022-05-15 00:00:00\n",
            "Length 2538736.\n",
            "\n",
            "Total target feature shape (2545020, 4)\n",
            "   FIPS       Date  Cases  Deaths\n",
            "0  1001 2020-02-28      0     0.0\n",
            "1  1003 2020-02-28      0     0.0\n",
            "2  1005 2020-02-28      0     0.0\n",
            "3  1007 2020-02-28      0     0.0\n",
            "4  1009 2020-02-28      0     0.0\n",
            "Merging all features\n",
            "Total merged data shape (2545020, 11)\n",
            "Missing percentage in total data\n",
            "VaccinationFull    35.68\n",
            "Deaths              0.25\n",
            "FIPS                0.00\n",
            "AgeDist             0.00\n",
            "HealthDisp          0.00\n",
            "Name                0.00\n",
            "Date                0.00\n",
            "DiseaseSpread       0.00\n",
            "Transmission        0.00\n",
            "SocialDist          0.00\n",
            "Cases               0.00\n",
            "dtype: float64\n",
            "Filling null values with 0\n",
            "Adding time based embeddings.\n"
          ]
        }
      ],
      "source": [
        "# if you have already created the total df one, and now just want to \n",
        "# reuse it to create different population or rurality cut\n",
        "if args.cachePath:\n",
        "    total_df = pd.read_csv(args.cachePath)\n",
        "else:\n",
        "    total_df = dataMerger.get_all_features()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL9QSxIv9Hom",
        "outputId": "2181bd9c-693d-4f95-dca7-be88bc40f7c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing total data to ../2022_May_target_cleaned/Total.csv\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output_path_total = os.path.join(args.outputPath, 'Total.csv') \n",
        "print(f'Writing total data to {output_path_total}\\n')\n",
        "total_df.round(4).to_csv(output_path_total, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-VF9mlz9Hon"
      },
      "source": [
        "## Rurality cut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAIzVVvS9Hon",
        "outputId": "10bb2b07-326b-4c5e-94c9-a834f23569eb"
      },
      "outputs": [],
      "source": [
        "# you can define \"Rurality cut\" in 'data'->'support'\n",
        "# \"Rurality cut\" has to be set true. and also set lower and upper limit in RuralityRange and/or MADRange\n",
        "# having -1 in either of these two will result in ignoring that key\n",
        "if dataMerger.need_rurality_cut():\n",
        "    rurality_df = dataMerger.rurality_cut(total_df)\n",
        "\n",
        "    output_path_rurality_cut = os.path.join(args.outputPath, 'Rurality_cut.csv')\n",
        "    print(f'Writing rurality cut data to {output_path_rurality_cut}\\n')\n",
        "    rurality_df.round(4).to_csv(output_path_rurality_cut, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGPpSPbM9Hoo"
      },
      "source": [
        "## Population cut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xiq0UbD9Hoo",
        "outputId": "22d626ea-bde1-4cf9-aa54-47ae3f217a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Slicing based on top 500 counties by population\n",
            "Writing population cut data to ../2022_May_target_cleaned/Top_500.csv\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# you can define 'Population cut' in 'data'->'support'\n",
        "# this means how many of top counties you want to keep\n",
        "\n",
        "# dataMerger.support_config['Population cut'] = 100\n",
        "\n",
        "if dataMerger.need_population_cut():\n",
        "    top_df = dataMerger.population_cut(total_df)\n",
        "    filename = f\"Top_{dataMerger.data_config.population_cut}.csv\"\n",
        "\n",
        "    output_path_population_cut = os.path.join(args.outputPath, filename)\n",
        "\n",
        "    print(f'Writing population cut data to {output_path_population_cut}\\n')\n",
        "    top_df.round(4).to_csv(output_path_population_cut, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Data preparation.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "f82c0d4b75d1a522b549257adf6e3ea321f1ee050a595ab76efcf522f2572b2a"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
